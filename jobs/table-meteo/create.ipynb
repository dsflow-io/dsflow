{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: this notebook was generated by dsflow*\n",
    "\n",
    "# meteo_bretagne / create_table\n",
    "\n",
    "## \\[1- config\\] get task configuration as defined in dag_specs.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_path': '/data/raw/meteo/ds=2017-09-23', 'sink_path': '/data/tables/meteo/ds=2017-09-23', 'ds': '2017-09-23'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ds = os.environ.get('INPUT_PARAMETER', \"2017-09-23\")\n",
    "\n",
    "# Get task configuration, as defined in dag_specs.yaml\n",
    "task_config={'source_path': \"/data/raw/meteo/ds=%s\" % ds,\n",
    "             'sink_path': \"/data/tables/meteo/ds=%s\" % ds,\n",
    "             'ds': ds}\n",
    "print(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get task variables:\n",
    "source_path = task_config[\"source_path\"]\n",
    "sink_path = task_config[\"sink_path\"]\n",
    "ds = task_config[\"ds\"]  # ds is the execution date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://public.opendatasoft.com/explore/dataset/donnees-synop-essentielles-omm/information/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[2- first data check\\] using Spark, print a couple lines from source_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = spark.read.text(source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[3- process data\\] convert raw data into a Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = (spark\n",
    ".read\n",
    ".options(wholeFile=True, inferSchema=True)\n",
    ".json(source_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1694"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datasetid: string (nullable = true)\n",
      " |-- fields: struct (nullable = true)\n",
      " |    |-- ch: string (nullable = true)\n",
      " |    |-- cl: string (nullable = true)\n",
      " |    |-- cm: string (nullable = true)\n",
      " |    |-- cod_tend: long (nullable = true)\n",
      " |    |-- coordonnees: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- ctype1: string (nullable = true)\n",
      " |    |-- ctype2: string (nullable = true)\n",
      " |    |-- ctype3: string (nullable = true)\n",
      " |    |-- ctype4: string (nullable = true)\n",
      " |    |-- date: string (nullable = true)\n",
      " |    |-- dd: long (nullable = true)\n",
      " |    |-- etat_sol: string (nullable = true)\n",
      " |    |-- ff: double (nullable = true)\n",
      " |    |-- hbas: string (nullable = true)\n",
      " |    |-- hnuage1: string (nullable = true)\n",
      " |    |-- hnuage2: string (nullable = true)\n",
      " |    |-- hnuage3: string (nullable = true)\n",
      " |    |-- hnuage4: string (nullable = true)\n",
      " |    |-- n: string (nullable = true)\n",
      " |    |-- nbas: string (nullable = true)\n",
      " |    |-- nnuage1: string (nullable = true)\n",
      " |    |-- nnuage2: string (nullable = true)\n",
      " |    |-- nnuage3: string (nullable = true)\n",
      " |    |-- nnuage4: string (nullable = true)\n",
      " |    |-- nom: string (nullable = true)\n",
      " |    |-- numer_sta: string (nullable = true)\n",
      " |    |-- per: string (nullable = true)\n",
      " |    |-- pmer: string (nullable = true)\n",
      " |    |-- pres: long (nullable = true)\n",
      " |    |-- raf10: string (nullable = true)\n",
      " |    |-- rafper: string (nullable = true)\n",
      " |    |-- rr1: double (nullable = true)\n",
      " |    |-- rr12: double (nullable = true)\n",
      " |    |-- rr24: double (nullable = true)\n",
      " |    |-- rr3: double (nullable = true)\n",
      " |    |-- rr6: double (nullable = true)\n",
      " |    |-- t: double (nullable = true)\n",
      " |    |-- td: double (nullable = true)\n",
      " |    |-- temps_passe_1: string (nullable = true)\n",
      " |    |-- temps_present: string (nullable = true)\n",
      " |    |-- tend: long (nullable = true)\n",
      " |    |-- tend24: long (nullable = true)\n",
      " |    |-- tn12: string (nullable = true)\n",
      " |    |-- tx12: string (nullable = true)\n",
      " |    |-- type_de_tendance_barometrique: string (nullable = true)\n",
      " |    |-- u: long (nullable = true)\n",
      " |    |-- vv: string (nullable = true)\n",
      " |    |-- w1: string (nullable = true)\n",
      " |    |-- w2: string (nullable = true)\n",
      " |    |-- ww: string (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- record_timestamp: string (nullable = true)\n",
      " |-- recordid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# by default, dataframe uses an auto-detected schema\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset02 = (dataset\n",
    "  .selectExpr(\"cast(fields.date as timestamp) as ts\",\n",
    "          \"date(cast(fields.date as date)) as record_date\",\n",
    "          \"fields.*\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- record_date: date (nullable = true)\n",
      " |-- ch: string (nullable = true)\n",
      " |-- cl: string (nullable = true)\n",
      " |-- cm: string (nullable = true)\n",
      " |-- cod_tend: long (nullable = true)\n",
      " |-- coordonnees: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ctype1: string (nullable = true)\n",
      " |-- ctype2: string (nullable = true)\n",
      " |-- ctype3: string (nullable = true)\n",
      " |-- ctype4: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- dd: long (nullable = true)\n",
      " |-- etat_sol: string (nullable = true)\n",
      " |-- ff: double (nullable = true)\n",
      " |-- hbas: string (nullable = true)\n",
      " |-- hnuage1: string (nullable = true)\n",
      " |-- hnuage2: string (nullable = true)\n",
      " |-- hnuage3: string (nullable = true)\n",
      " |-- hnuage4: string (nullable = true)\n",
      " |-- n: string (nullable = true)\n",
      " |-- nbas: string (nullable = true)\n",
      " |-- nnuage1: string (nullable = true)\n",
      " |-- nnuage2: string (nullable = true)\n",
      " |-- nnuage3: string (nullable = true)\n",
      " |-- nnuage4: string (nullable = true)\n",
      " |-- nom: string (nullable = true)\n",
      " |-- numer_sta: string (nullable = true)\n",
      " |-- per: string (nullable = true)\n",
      " |-- pmer: string (nullable = true)\n",
      " |-- pres: long (nullable = true)\n",
      " |-- raf10: string (nullable = true)\n",
      " |-- rafper: string (nullable = true)\n",
      " |-- rr1: double (nullable = true)\n",
      " |-- rr12: double (nullable = true)\n",
      " |-- rr24: double (nullable = true)\n",
      " |-- rr3: double (nullable = true)\n",
      " |-- rr6: double (nullable = true)\n",
      " |-- t: double (nullable = true)\n",
      " |-- td: double (nullable = true)\n",
      " |-- temps_passe_1: string (nullable = true)\n",
      " |-- temps_present: string (nullable = true)\n",
      " |-- tend: long (nullable = true)\n",
      " |-- tend24: long (nullable = true)\n",
      " |-- tn12: string (nullable = true)\n",
      " |-- tx12: string (nullable = true)\n",
      " |-- type_de_tendance_barometrique: string (nullable = true)\n",
      " |-- u: long (nullable = true)\n",
      " |-- vv: string (nullable = true)\n",
      " |-- w1: string (nullable = true)\n",
      " |-- w2: string (nullable = true)\n",
      " |-- ww: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset02.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|record_date|count|\n",
      "+-----------+-----+\n",
      "| 2017-01-06|    8|\n",
      "| 2017-01-27|    8|\n",
      "| 2017-02-26|    8|\n",
      "| 2017-01-24|    8|\n",
      "| 2017-06-29|    8|\n",
      "| 2017-02-16|    8|\n",
      "| 2017-07-31|    8|\n",
      "| 2017-04-09|    8|\n",
      "| 2017-03-28|    8|\n",
      "| 2017-02-28|    8|\n",
      "| 2017-06-30|    8|\n",
      "| 2017-01-30|    8|\n",
      "| 2017-07-06|    8|\n",
      "| 2017-05-11|    8|\n",
      "| 2017-02-10|    8|\n",
      "| 2017-04-25|    8|\n",
      "| 2017-03-19|    8|\n",
      "| 2017-05-26|    8|\n",
      "| 2017-01-04|    8|\n",
      "| 2017-06-28|    8|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset02.groupby(\"record_date\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a303e49b941d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdsflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dsflow' is not defined"
     ]
    }
   ],
   "source": [
    "dsflow.display(dataset02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7fee54f5a2d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdsflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset02\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dsflow' is not defined"
     ]
    }
   ],
   "source": [
    "dsflow.display(dataset02.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[4- write on disk\\] write down the output to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_dataset = dataset02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(final_dataset\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .parquet(sink_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
